想象一下，你偶然发现了一个电影剧本短片，它

描述了一个人和他的人工智能助手之间的场景。

剧本里有这个人向人工智能提出的问题，但人工智能的回答却被撕掉了。

假设你也有一台功能强大的神奇机器，它能

任何文本，并合理预测下一个单词是什么。

然后，您就可以向机器输入所需的内容，完成脚本、

看它会预测什么来启动人工智能的答案、

然后一遍又一遍地重复，用不断增加的脚本来完成对话。

当你与聊天机器人互动时，这正是正在发生的事情。

大型语言模型是一个复杂的数学函数

它能预测任何文本的下一个单词。

不过，我们并不能肯定地预测一个词、

它的作用是为所有可能的下一个词分配一个概率。

要创建一个聊天机器人，你需要编写一些文本，描述用户之间的交互过程

和一个假想的人工智能助手，将用户输入的任何内容添加为

互动，然后让模型反复预测下一个单词，这样的

假想的人工智能助手会说什么，用户就会听到什么。

这样做的结果往往看起来更自然，如果

你可以让它沿途随机选择不太可能出现的单词。

因此，这意味着即使模型本身是确定性的、

每次运行某个提示时，给出的答案通常都不同。

模型通过处理大量文本来学习如何做出这些预测、

通常是从互联网上下载的。

对于一个标准人来说，阅读的文字量与训练 GPT-3 所用的文字量相当、

例如，如果他们 24 小时不停地阅读，则需要 2600 多年。

从那时起，更大型的机型的训练内容要多得多。

你可以把训练想象成调试一台大机器上的刻度盘。

语言模型的行为方式完全由以下因素决定

许多不同的连续值，通常称为参数或权重。

改变这些参数将改变概率

模型根据给定输入给出的下一个单词。

大型语言模型中的 "大型 "是指

它们可以有数千亿个这样的参数。

没有人会故意设置这些参数。

相反，它们是随机开始的，这意味着模型只会输出胡言乱语、

但它们是在许多文本示例的基础上反复推敲出来的。

其中一个训练示例可能只是寥寥数语、

也可能是成千上万，但无论哪种情况，其工作方式都是

将该示例中除最后一个字以外的所有内容输入模型，并

将其预测结果与示例中最后一个词的真实值进行比较。

使用一种名为反向传播的算法来调整所有参数

使模型更有可能选择

真正的最后一个词，而不太可能选择其他所有词。

当你对数以万亿计的例子进行计算时、

不仅如此，模型还能开始对训练数据做出更准确的预测、

但它也开始对文本进行更合理的预测，而它从来没有

见过的。

鉴于参数数量庞大，训练数据量巨大、

训练一个大型语言模型所需的计算量是惊人的。

为了说明这一点，想象一下您可以执行一个

每秒进行十亿次加法和乘法运算。

你认为你需要多长时间才能完成所有的

训练最大语言模型涉及哪些操作？

你认为这需要一年时间吗？

也许是一万年？

答案其实远不止这些。

已经超过一亿年了。

不过，这只是故事的一部分。

整个过程称为预培训。

自动完成一段随机文本的目标是

互联网与成为优秀的人工智能助手的目标截然不同。

为了解决这个问题，聊天机器人需要接受另一种培训、

同样重要的是，"人的反馈强化学习"。

工人对无益或有问题的预测进行标记、

及其修正进一步改变了模型参数、

使它们更有可能提供用户喜欢的预测。

不过，回顾培训前的情况，这些数量惊人的

只有使用特殊的计算机芯片才能进行计算。

GPU 是为并行运行许多操作而优化的。

然而，并非所有语言模型都能轻松实现并行化。

2017 年之前，大多数语言模型都是一个词一个词地处理文本、

但后来，谷歌的一个研究团队推出了一种被称为 "变压器 "的新模式。

变形金刚不会从头到尾阅读文字、

他们会同时、并行地吸收所有信息。

这是变压器和大多数其他语言模型的第一步、

就是将每个单词与一长串数字联系起来。

原因是训练过程只适用于连续值、

因此，你必须用数字对语言进行编码、

而这些数字列表中的每一个都可能以某种方式编码了

相应的词。

变压器的独特之处在于它们依靠

一种被称为 "注意力 "的特殊操作。

该操作让所有这些数字列表有机会相互对话

并根据周围的语境完善它们所编码的含义，所有这些都是同步进行的。

例如，编码词库的数字可能会根据

它周围的语境以某种方式编码了河岸这一更为具体的概念。

变压器通常还包括第二种运行方式，即

作为一个前馈神经网络，这就为模型提供了额外的

能够存储更多在训练中学到的语言模式。

所有这些数据都会反复流经许多不同的

在进行这两项基本操作时、

希望每一个数字列表都能被丰富，以编码任何

要准确预测什么词可能需要的信息

在该段中如下。

最后，对序列中的最后一个向量执行最后一个函数、

现在有机会受到输入文本中所有其他上下文的影响、

以及模型在训练过程中学到的所有知识、

来预测下一个单词。

同样，模型的预测看起来就像是每个可能的下一个单词的概率。

尽管研究人员为这些步骤中的每一步设计了工作框架、

重要的是要明白，具体行为是一种新出现的现象

基于在训练过程中如何调整这些千亿级参数。

这使得确定

为什么模型能做出准确的预测。

您可以看到，当您使用大型语言模型预测来自动完成

提示，它所产生的词语却异常流畅、引人入胜，甚至非常有用。

如果您是新观众，并想了解更多关于如何

变压器和注意力工作，我有一些材料要给你们。

一种方法是跳进我制作的深度学习系列、

在这里，我们将注意力的细节和所有其他步骤可视化并加以激励

在变压器中。

另外，在我的第二个频道上，我刚刚发布了我在几个月前发表的演讲。

几个月前，我曾为慕尼黑的 TNG 公司做过关于这个主题的演讲。

有时，我其实更喜欢把自己制作的内容当作一次随意的谈话，而不是制作出来的

视频，但我让你们自己决定哪一个更像后续节目。


